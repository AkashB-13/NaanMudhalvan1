{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWrjaaNUHuZGhS4xsqSeKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkashB-13/NaanMudhalvan1/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import scipy.sparse as sparse\n",
        "import implicit\n",
        "import requests\n",
        "\n",
        "# Load data\n",
        "movies = pd.read_csv('movie.csv')\n",
        "ratings = pd.read_csv('rating.csv')\n",
        "tmdb_movies = pd.read_csv('tmdb_5000_movies.csv')\n",
        "tmdb_credits = pd.read_csv('tmdb_5000_credits.csv')\n",
        "links = pd.read_csv('link.csv')\n",
        "\n",
        "# Merge TMDB data\n",
        "tmdb = tmdb_movies.merge(tmdb_credits, left_on='id', right_on='movie_id', how='left')\n",
        "links = links.dropna(subset=['tmdbId'])\n",
        "links['tmdbId'] = links['tmdbId'].astype(int)\n",
        "tmdb['id'] = tmdb['id'].astype(int)\n",
        "df = links.merge(tmdb, left_on='tmdbId', right_on='id')\n",
        "\n",
        "# Helper functions\n",
        "def get_director(x):\n",
        "    for i in ast.literal_eval(x):\n",
        "        if i['job'] == 'Director':\n",
        "            return i['name']\n",
        "    return ''\n",
        "\n",
        "def get_top_cast(x):\n",
        "    return [i['name'] for i in ast.literal_eval(x)[:3]]\n",
        "\n",
        "def parse_genres(x):\n",
        "    return [i['name'] for i in ast.literal_eval(x)]\n",
        "\n",
        "# Fill missing values and extract features\n",
        "df['crew'] = df['crew'].fillna('[]')\n",
        "df['cast'] = df['cast'].fillna('[]')\n",
        "df['genres'] = df['genres'].fillna('[]')\n",
        "df['overview'] = df['overview'].fillna('')\n",
        "df['director'] = df['crew'].apply(get_director)\n",
        "df['cast'] = df['cast'].apply(get_top_cast)\n",
        "df['genres'] = df['genres'].apply(parse_genres)\n",
        "\n",
        "def create_tags(row):\n",
        "    cast = ' '.join(row['cast']) if isinstance(row['cast'], list) else ''\n",
        "    genres = ' '.join(row['genres']) if isinstance(row['genres'], list) else ''\n",
        "    return f\"{cast} {row['director']} {genres} {row['overview']}\"\n",
        "\n",
        "df['tags'] = df.apply(create_tags, axis=1)\n",
        "\n",
        "# TF-IDF and cosine similarity\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "tfidf_matrix = vectorizer.fit_transform(df['tags'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# ALS model prep\n",
        "ratings['implicit_rating'] = ratings['rating']\n",
        "user_ids = ratings['userId'].unique()\n",
        "movie_ids = ratings['movieId'].unique()\n",
        "user_to_idx = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
        "movie_to_idx = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}\n",
        "ratings['user_idx'] = ratings['userId'].map(user_to_idx)\n",
        "ratings['movie_idx'] = ratings['movieId'].map(movie_to_idx)\n",
        "\n",
        "sparse_matrix = sparse.coo_matrix(\n",
        "    (ratings['implicit_rating'].astype(float),\n",
        "     (ratings['movie_idx'], ratings['user_idx']))\n",
        ")\n",
        "\n",
        "als_model = implicit.als.AlternatingLeastSquares(\n",
        "    factors=50,\n",
        "    regularization=0.1,\n",
        "    iterations=20,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "sparse_matrix_csr = sparse_matrix.tocsr()\n",
        "als_model.fit(sparse_matrix_csr)\n",
        "\n",
        "# Save data\n",
        "with open('cosine_sim.pkl', 'wb') as f:\n",
        "    pickle.dump(cosine_sim, f)\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "with open('als_model.pkl', 'wb') as f:\n",
        "    pickle.dump(als_model, f)\n",
        "\n",
        "with open('user_to_idx.pkl', 'wb') as f:\n",
        "    pickle.dump(user_to_idx, f)\n",
        "\n",
        "with open('movie_to_idx.pkl', 'wb') as f:\n",
        "    pickle.dump(movie_to_idx, f)\n",
        "\n",
        "df.to_pickle('movies_df.pkl')\n",
        "\n",
        "# Fetch posters\n",
        "tmdb_api_key = \"fd09c6f07ac096efb6bf5af91fa69803\"\n",
        "\n",
        "def fetch_poster_url(tmdb_id, api_key):\n",
        "    try:\n",
        "        url = f\"https://api.themoviedb.org/3/movie/{tmdb_id}?api_key={api_key}\"\n",
        "        response = requests.get(url, timeout=5)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        poster_path = data.get('poster_path')\n",
        "        if poster_path:\n",
        "            return f\"https://image.tmdb.org/t/p/w500{poster_path}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching poster for TMDB ID {tmdb_id}: {e}\")\n",
        "    return \"https://via.placeholder.com/500x750?text=No+Image\"\n",
        "\n",
        "print(\"Fetching poster URLs for movies...\")\n",
        "poster_urls = {tmdb_id: fetch_poster_url(tmdb_id, tmdb_api_key) for tmdb_id in df['tmdbId'].unique()}\n",
        "df['poster_url'] = df['tmdbId'].map(poster_urls)\n",
        "df.to_pickle('movies_with_posters.pkl')\n",
        "print(\"Done! Saved movies_with_posters.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "9iktlvRpDtym",
        "outputId": "a96316f9-1d48-4368-8889-540505102344"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-f22b974cab45>, line 110)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f22b974cab45>\"\u001b[0;36m, line \u001b[0;32m110\u001b[0m\n\u001b[0;31m    oduleNotFoundError                       Traceback (most recent call last)\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}